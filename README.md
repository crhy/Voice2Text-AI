# Voice2Text AI

<img src="logo.png" alt="Voice2Text AI Logo" width="200"/>

A cross-platform Python application that transcribes voice input using GPU-accelerated Whisper, sends text to local Ollama AI models for intelligent responses, and reads the output aloud with text-to-speech.

## Features

- üéôÔ∏è Real-time voice transcription with OpenAI Whisper (GPU-accelerated)
- ü§ñ AI chat integration with local Ollama models
- üîä Text-to-speech output with pause/resume
- üé® Modern dark gradient UI
- üì¶ Cross-platform executables (Windows/macOS/Linux)
- üñ•Ô∏è Flatpak support
- ‚ö° Optimized performance with silence detection
- üîÑ Automatic retry logic for network requests



## Requirements

- Python 3.8+ (maybe, I think the standalone app runs without it)
- Ollama running locally (http://localhost:11434) (only for AI interaction)
- Microphone access (The whole point is dictation)
- CUDA-compatible GPU (optional, for faster Whisper processing.  Highly recommended.)

## Installation

### Pre-built Executables
Download the latest release from [GitHub Releases](https://github.com/crhy/Voice2Text-AI/releases):
- **Windows**: `Voice2Text.exe` Untested
- **macOS**: `Voice2Text` Untested
- **Linux**: 'Voice2Text' https://drive.google.com/file/d/1MmF6Vr_3nz1yket2SdnHCI_Od5OpIzQd/view?usp=sharing

### Linux (Flatpak) (ToDo)
```bash
# Install from Flathub (when available)
flatpak install flathub com.voice2text.app

# Or download from GitHub Releases
# Download: voice2text.flatpak from latest release
# Install: flatpak install --user voice2text.flatpak
# Run: flatpak run com.voice2text.app
```

### From Source (This might actually work)
```bash
git clone https://github.com/crhy/Voice2Text-AI.git
cd Voice2Text-AI
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### Development
```bash
# Run tests
python test_voice.py
python test_mic.py
python test_whisper.py

# Build executable
pyinstaller voice_app.spec

# Build Flatpak (This has never worked.  Yet)
flatpak-builder --force-clean build com.voice2text.app.yml
flatpak-builder --user --install build com.voice2text.app.yml

# Export Flatpak for distribution
flatpak build-bundle build voice2text.flatpak com.voice2text.app
```

### Setup Ollama
```bash
# Install Ollama (if not already installed)
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service
ollama serve

# Pull a model (in another terminal)
ollama pull llama3.2  # or any preferred model
```

## Usage

### Running the App
- **Executable**: Right Click, Select "Allow Executing File as Program", Double-click the downloaded file (wait, it's slow to load.  Once it's up it's crazy fast)
- **From Source**: `python voice_app.py`
- **Flatpak**: `flatpak run com.voice2text.app` (Good luck?)

### Quick Start
1. Select your Ollama model from the dropdown
2. Click "üéôÔ∏è Start Dictation"
3. Speak clearly into your microphone
4. Click "‚èπÔ∏è Stop Dictation" when finished
5. Click "ü§ñ Query AI" to get AI responses
6. Responses are displayed and spoken aloud

The app automatically saves your settings and provides real-time status updates.

## Notes

- Whisper models run locally (internet required for initial download)
- Edge TTS provides local speech synthesis
- GPU acceleration speeds up transcription significantly
- Settings persist between sessions
- App works offline after initial model downloads

## Troubleshooting

- **Microphone**: Run `python test_mic.py`
- **Ollama**: Ensure it's running at `http://localhost:11434`
- **GPU**: Check with `nvidia-smi` (optional)
- **Audio**: Grant microphone permissions
- **Models**: First run downloads Whisper models (~2GB)

## Project Structure

```
Voice2Text-AI/
‚îú‚îÄ‚îÄ voice_app.py          # Main GUI application
‚îú‚îÄ‚îÄ main.py              # Alternative Tkinter version
‚îú‚îÄ‚îÄ voice_app_kivy.py    # Kivy mobile version
‚îú‚îÄ‚îÄ voice_to_opencode.py  # CLI version
‚îú‚îÄ‚îÄ requirements.txt      # Python dependencies
‚îú‚îÄ‚îÄ test_*.py            # Test scripts
‚îú‚îÄ‚îÄ *.spec               # PyInstaller configs
‚îú‚îÄ‚îÄ *.desktop            # Linux desktop files
‚îú‚îÄ‚îÄ com.voice2text.app.*  # Flatpak manifests
‚îú‚îÄ‚îÄ config.json          # App configuration
‚îú‚îÄ‚îÄ voice_config.json    # Voice app settings
‚îú‚îÄ‚îÄ logo.png             # Application logo
‚îú‚îÄ‚îÄ install.sh           # Linux installer
‚îî‚îÄ‚îÄ README.md
```

## Distribution

### Building Releases
```bash
# Create GitHub release with all platform binaries
# Upload these files to GitHub Releases:
# - Voice2Text.exe (Windows)
# - Voice2Text (macOS)
# - voice2text.flatpak (Linux)
```

### Flathub Submission
To submit to Flathub for official distribution:
```bash
# Fork the Flathub repository
# Add your manifest to: https://github.com/flathub/flathub
# Submit pull request with com.voice2text.app.yml
```

## Contributing

Contributions welcome! Please submit issues and pull requests on [GitHub](https://github.com/crhy/Voice2Text-AI).

## License

This project is open source. See individual files for license information.
